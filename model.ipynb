{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e968b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import prepare2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92643c63",
   "metadata": {},
   "source": [
    "### Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b5a769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = acquire.get_titanic_data()\n",
    "df = titanic_data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9236d295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pulled and updated from prepare.py - was having some issues with the string 'sex' when splitting\n",
    "\n",
    "def clean_data(df):\n",
    "    '''\n",
    "    This function will clean the data etc etc...'''\n",
    "    df = df.drop_duplicates()\n",
    "    cols_to_drop = ['deck', 'embarked', 'class']\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    df['baseline_prediction'] = 0\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True,True])\n",
    "    #df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df = df.drop(columns = ['sex', 'embark_town'])\n",
    "    df.age = df.age.fillna(value=df.age.median())\n",
    "    return df\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8531f0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass   age  sibsp  parch     fare  alone  \\\n",
       "0               0         0       3  22.0      1      0   7.2500      0   \n",
       "1               1         1       1  38.0      1      0  71.2833      0   \n",
       "2               2         1       3  26.0      0      0   7.9250      1   \n",
       "3               3         1       1  35.0      1      0  53.1000      0   \n",
       "4               4         0       3  35.0      0      0   8.0500      1   \n",
       "..            ...       ...     ...   ...    ...    ...      ...    ...   \n",
       "886           886         0       2  27.0      0      0  13.0000      1   \n",
       "887           887         1       1  19.0      0      0  30.0000      1   \n",
       "888           888         0       3  28.0      1      2  23.4500      0   \n",
       "889           889         1       1  26.0      0      0  30.0000      1   \n",
       "890           890         0       3  32.0      0      0   7.7500      1   \n",
       "\n",
       "     baseline_prediction  sex_male  embark_town_Queenstown  \\\n",
       "0                      0         1                       0   \n",
       "1                      0         0                       0   \n",
       "2                      0         0                       0   \n",
       "3                      0         0                       0   \n",
       "4                      0         1                       0   \n",
       "..                   ...       ...                     ...   \n",
       "886                    0         1                       0   \n",
       "887                    0         0                       0   \n",
       "888                    0         0                       0   \n",
       "889                    0         1                       0   \n",
       "890                    0         1                       1   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  \n",
       "..                       ...  \n",
       "886                        1  \n",
       "887                        1  \n",
       "888                        1  \n",
       "889                        0  \n",
       "890                        0  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3032c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.age = df.age.fillna(value=df.age.median())\n",
    "# df = df.drop(columns = ['deck', 'embarked'])\n",
    "# df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12415a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reduce obvious noise\n",
    "# df = df.set_index(\"passenger_id\")\n",
    "# df = df.drop(columns=[\"class\", \"embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19211436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop deck because there are far too many nulls\n",
    "# df = df.drop(columns=[\"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffe0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's fill embark_town with the most common observation\n",
    "# df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's investigate the observations with missing age\n",
    "# # My first thought was empty age values might indicate children\n",
    "# # Looks like most of these individuals were traveling alone\n",
    "# no_age_info = df[df.age.isna()]\n",
    "# no_age_info.alone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed4d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Time to encode the encodeable!\n",
    "# dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# # Drop the original columns we encoded\n",
    "# df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "\n",
    "# # Stitch the df and the dummy_df together again\n",
    "# df = pd.concat([df, dummy_df], axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82e795e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id               0\n",
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "baseline_prediction        0\n",
       "sex_male                   0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What about nulls?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e5cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a22172",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd00bf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass   age  sibsp  parch      fare  alone  \\\n",
       "583           583         0       1  36.0      0      0   40.1250      1   \n",
       "165           165         1       3   9.0      0      2   20.5250      0   \n",
       "50             50         0       3   7.0      4      1   39.6875      0   \n",
       "259           259         1       2  50.0      0      1   26.0000      0   \n",
       "306           306         1       1  28.0      0      0  110.8833      1   \n",
       "\n",
       "     baseline_prediction  sex_male  embark_town_Queenstown  \\\n",
       "583                    0         1                       0   \n",
       "165                    0         1                       0   \n",
       "50                     0         1                       0   \n",
       "259                    0         0                       0   \n",
       "306                    0         0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "583                        0  \n",
       "165                        1  \n",
       "50                         1  \n",
       "259                        1  \n",
       "306                        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d87b4",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b3c230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline is simpliest model\n",
    "#runs a .mode on y_train and saves to baseline\n",
    "#what is the likely prediction here? more likely someone died or survived?\n",
    "#simplest model is featureless model were they on the titanic? did they die? - will be right 62% of th time\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11610dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0eb11a",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed1394ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   passenger_id             498 non-null    int64  \n",
      " 1   survived                 498 non-null    int64  \n",
      " 2   pclass                   498 non-null    int64  \n",
      " 3   age                      498 non-null    float64\n",
      " 4   sibsp                    498 non-null    int64  \n",
      " 5   parch                    498 non-null    int64  \n",
      " 6   fare                     498 non-null    float64\n",
      " 7   alone                    498 non-null    int64  \n",
      " 8   baseline_prediction      498 non-null    int64  \n",
      " 9   sex_male                 498 non-null    uint8  \n",
      " 10  embark_town_Queenstown   498 non-null    uint8  \n",
      " 11  embark_town_Southampton  498 non-null    uint8  \n",
      "dtypes: float64(2), int64(7), uint8(3)\n",
      "memory usage: 40.4 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4c0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = tree1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a85d3",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f948e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e4134f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  265   42\n",
       "1   58  133"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix - actual on left, predicted on top\n",
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea82a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4a2de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.797255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.696335</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.779764</td>\n",
       "      <td>0.799197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.797358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
       "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
       "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
       "support    307.000000  191.000000  0.799197  498.000000    498.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89cf8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c05f9ad1",
   "metadata": {},
   "source": [
    "one depth tree is able to get it right 80% of the time - could be asking are you male or female?\n",
    "\n",
    "-add confusion matrix - (actual on left, predicted on the top = reference to how Adam has his code lined)\n",
    "code18 isn't necessary just depends on how you like to visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0955045",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e9e39ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  265   42\n",
       "1   58  133"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e16224a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7991967871485943\n",
      "True Positive Rate: 0.8631921824104235\n",
      "False Positive Rate: 0.3036649214659686\n",
      "True Negative Rate: 0.6963350785340314\n",
      "False Negative Rate: 0.13680781758957655\n",
      "Precision: 0.8204334365325078\n",
      "Recall: 0.8631921824104235\n",
      "F1 Score: 0.8412698412698413\n",
      "Support (0): 307\n",
      "Support (1): 191\n"
     ]
    }
   ],
   "source": [
    "# If not-survived is our positive case\n",
    "TP = 265\n",
    "FP = 58\n",
    "FN = 42\n",
    "TN = 133\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a3fb9",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6eeb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the difference is the overfitting of the model\n",
    "\n",
    "#how do we make the judgement call on which model works best? - no hard and fast anwser \n",
    "#focus on the difference number (<.10) could offer us models that aren't overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc4489ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
      "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
      "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
      "support    307.000000  191.000000  0.799197  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.853211    0.836257   0.84739    0.844734      0.846709\n",
      "recall       0.908795    0.748691   0.84739    0.828743      0.847390\n",
      "f1-score     0.880126    0.790055   0.84739    0.835091      0.845581\n",
      "support    307.000000  191.000000   0.84739  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.836158    0.923611  0.861446    0.879885      0.869699\n",
      "recall       0.964169    0.696335  0.861446    0.830252      0.861446\n",
      "f1-score     0.895613    0.794030  0.861446    0.844821      0.856652\n",
      "support    307.000000  191.000000  0.861446  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.870091    0.886228  0.875502    0.878159      0.876280\n",
      "recall       0.938111    0.774869  0.875502    0.856490      0.875502\n",
      "f1-score     0.902821    0.826816  0.875502    0.864818      0.873671\n",
      "support    307.000000  191.000000  0.875502  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.905063    0.884615   0.89759    0.894839      0.897221\n",
      "recall       0.931596    0.842932   0.89759    0.887264      0.897590\n",
      "f1-score     0.918138    0.863271   0.89759    0.890704      0.897095\n",
      "support    307.000000  191.000000   0.89759  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.911043    0.941860  0.921687    0.926452      0.922863\n",
      "recall       0.967427    0.848168  0.921687    0.907797      0.921687\n",
      "f1-score     0.938389    0.892562  0.921687    0.915475      0.920813\n",
      "support    307.000000  191.000000  0.921687  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.943574    0.966480  0.951807    0.955027      0.952359\n",
      "recall       0.980456    0.905759  0.951807    0.943108      0.951807\n",
      "f1-score     0.961661    0.935135  0.951807    0.948398      0.951488\n",
      "support    307.000000  191.000000  0.951807  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.944272    0.988571  0.959839    0.966422      0.961263\n",
      "recall       0.993485    0.905759  0.959839    0.949622      0.959839\n",
      "f1-score     0.968254    0.945355  0.959839    0.956805      0.959472\n",
      "support    307.000000  191.000000  0.959839  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 11\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.971338    0.989130  0.977912    0.980234      0.978162\n",
      "recall       0.993485    0.952880  0.977912    0.973182      0.977912\n",
      "f1-score     0.982287    0.970667  0.977912    0.976477      0.977830\n",
      "support    307.000000  191.000000  0.977912  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 12\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.983923    0.994652  0.987952    0.989288      0.988038\n",
      "recall       0.996743    0.973822  0.987952    0.985282      0.987952\n",
      "f1-score     0.990291    0.984127  0.987952    0.987209      0.987927\n",
      "support    307.000000  191.000000  0.987952  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 13\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.987138    1.000000  0.991968    0.993569      0.992071\n",
      "recall       1.000000    0.979058  0.991968    0.989529      0.991968\n",
      "f1-score     0.993528    0.989418  0.991968    0.991473      0.991951\n",
      "support    307.000000  191.000000  0.991968  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 14\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.996753    1.000000  0.997992    0.998377      0.997998\n",
      "recall       1.000000    0.994764  0.997992    0.997382      0.997992\n",
      "f1-score     0.998374    0.997375  0.997992    0.997875      0.997991\n",
      "support    307.000000  191.000000  0.997992  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 15\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    307.0  191.0       1.0      498.0         498.0\n",
      "\n",
      "Tree with max depth of 16\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    307.0  191.0       1.0      498.0         498.0\n",
      "\n",
      "Tree with max depth of 17\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    307.0  191.0       1.0      498.0         498.0\n",
      "\n",
      "Tree with max depth of 18\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    307.0  191.0       1.0      498.0         498.0\n",
      "\n",
      "Tree with max depth of 19\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    307.0  191.0       1.0      498.0         498.0\n",
      "\n",
      "Tree with max depth of 20\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    307.0  191.0       1.0      498.0         498.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's \n",
    "for i in range(2, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546157f",
   "metadata": {},
   "source": [
    "#### 6. Which model performs better on your in-sample data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "848a2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth of 15+ produces the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb6eba",
   "metadata": {},
   "source": [
    "#### 7. Which model performs best on your out-of-sample data, the validate set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f223406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.057670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.090418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.875502</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.095128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.897590</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.126562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.150659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.951807</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.185452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.959839</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.193484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.977912</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.220902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.249634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.244304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.269020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.261682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.799197           0.761682    0.037515\n",
       "1           3        0.825301           0.799065    0.026236\n",
       "2           4        0.847390           0.789720    0.057670\n",
       "3           5        0.861446           0.771028    0.090418\n",
       "4           6        0.875502           0.780374    0.095128\n",
       "5           7        0.897590           0.771028    0.126562\n",
       "6           8        0.921687           0.771028    0.150659\n",
       "7           9        0.951807           0.766355    0.185452\n",
       "8          10        0.959839           0.766355    0.193484\n",
       "9          11        0.977912           0.757009    0.220902\n",
       "10         12        0.987952           0.738318    0.249634\n",
       "11         13        0.991968           0.747664    0.244304\n",
       "12         14        0.997992           0.728972    0.269020\n",
       "13         15        1.000000           0.738318    0.261682\n",
       "14         16        1.000000           0.738318    0.261682\n",
       "15         17        1.000000           0.738318    0.261682\n",
       "16         18        1.000000           0.738318    0.261682\n",
       "17         19        1.000000           0.738318    0.261682\n",
       "18         20        1.000000           0.738318    0.261682\n",
       "19         21        1.000000           0.738318    0.261682\n",
       "20         22        1.000000           0.738318    0.261682\n",
       "21         23        1.000000           0.738318    0.261682\n",
       "22         24        1.000000           0.738318    0.261682"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c15b4b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.057670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.875502</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.095128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.090418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_accuracy  validate_accuracy  difference\n",
       "1          3        0.825301           0.799065    0.026236\n",
       "2          4        0.847390           0.789720    0.057670\n",
       "4          6        0.875502           0.780374    0.095128\n",
       "3          5        0.861446           0.771028    0.090418\n",
       "0          2        0.799197           0.761682    0.037515"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20af730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dddb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f5dbd4b",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "#### - 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5180c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0965f4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fa73ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    This function will clean the data etc etc...'''\n",
    "    df = df.drop_duplicates()\n",
    "    cols_to_drop = ['deck', 'embarked', 'class']\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    df['baseline_prediction'] = 0\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True,True])\n",
    "    #df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df = df.drop(columns = ['sex', 'embark_town'])\n",
    "    df.age = df.age.fillna(value=df.age.median())\n",
    "    return df\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fede972d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   age  sibsp  parch     fare  alone  \\\n",
       "0             0         0       3  22.0      1      0   7.2500      0   \n",
       "1             1         1       1  38.0      1      0  71.2833      0   \n",
       "2             2         1       3  26.0      0      0   7.9250      1   \n",
       "3             3         1       1  35.0      1      0  53.1000      0   \n",
       "4             4         0       3  35.0      0      0   8.0500      1   \n",
       "\n",
       "   baseline_prediction  sex_male  embark_town_Queenstown  \\\n",
       "0                    0         1                       0   \n",
       "1                    0         0                       0   \n",
       "2                    0         0                       0   \n",
       "3                    0         0                       0   \n",
       "4                    0         1                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcbe1b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "rf1_clf = RandomForestClassifier(max_depth=10, min_samples_leaf=1, random_state=123) \n",
    "rf1_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4feb25ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model (on train and only train)\n",
    "rf1_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a948672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16071359 0.08058682 0.14968253 0.05010018 0.02828417 0.18920115\n",
      " 0.01930141 0.         0.28922054 0.01281023 0.02009939]\n"
     ]
    }
   ],
   "source": [
    "print(rf1_clf.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26678bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model's performance on train, first\n",
    "y_pred_proba = rf1_clf.predict_proba(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77bec6",
   "metadata": {},
   "source": [
    "#### - 2. Evaluate your results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8314a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.962382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.981191</td>\n",
       "      <td>0.976810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937173</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.968586</td>\n",
       "      <td>0.975904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.980831</td>\n",
       "      <td>0.967568</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.974199</td>\n",
       "      <td>0.975744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.962382    1.000000  0.975904    0.981191      0.976810\n",
       "recall       1.000000    0.937173  0.975904    0.968586      0.975904\n",
       "f1-score     0.980831    0.967568  0.975904    0.974199      0.975744\n",
       "support    307.000000  191.000000  0.975904  498.000000    498.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30c12cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  307   12\n",
       "1    0  179"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7605e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf1_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1321bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "735fe863",
   "metadata": {},
   "source": [
    "#### - 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd265aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 307, 0, 12)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_predictions).ravel()\n",
    "#ravel changes to 2 dimensional array\n",
    "\n",
    "All = TP + TN + FP +FN\n",
    "\n",
    "TP, TN, FP, FN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "852546ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "The True Negative Rate is 1.0\n",
      "The True Positive Rate is 0.93717277486911\n",
      "The False Negative Rate is 0.06282722513089005\n",
      "The False Positive Rate is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "print('------------------------')\n",
    "print(f'The True Negative Rate is {TNR}')\n",
    "print(f'The True Positive Rate is {TPR}')\n",
    "print(f'The False Negative Rate is {FNR}')\n",
    "print(f'The False Positive Rate is {FPR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f82de6",
   "metadata": {},
   "source": [
    "## pulled from review:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2208c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 280, 27, 82)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = 109\n",
    "TN = 280\n",
    "FP = 27\n",
    "FN = 82\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b1397",
   "metadata": {},
   "source": [
    "#### - 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "72221bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7811244979919679\n",
      "True Positive Rate: 0.5706806282722513\n",
      "False Positive Rate: 0.08794788273615635\n",
      "True Negative Rate: 0.9120521172638436\n",
      "False Negative Rate: 0.4293193717277487\n",
      "Precision: 0.8014705882352942\n",
      "Recall: 0.5706806282722513\n",
      "F1 Score: 0.6666666666666667\n",
      "Support (0): 191\n",
      "Support (1): 307\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10831254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.790191    0.870229  0.811245    0.830210      0.820888\n",
      "recall       0.944625    0.596859  0.811245    0.770742      0.811245\n",
      "f1-score     0.860534    0.708075  0.811245    0.784304      0.802061\n",
      "support    307.000000  191.000000  0.811245  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.824207    0.860927  0.835341    0.842567      0.838291\n",
      "recall       0.931596    0.680628  0.835341    0.806112      0.835341\n",
      "f1-score     0.874618    0.760234  0.835341    0.817426      0.830748\n",
      "support    307.000000  191.000000  0.835341  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.843195    0.862500  0.849398    0.852848      0.850599\n",
      "recall       0.928339    0.722513  0.849398    0.825426      0.849398\n",
      "f1-score     0.883721    0.786325  0.849398    0.835023      0.846366\n",
      "support    307.000000  191.000000  0.849398  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.849858    0.951724  0.879518    0.900791      0.888927\n",
      "recall       0.977199    0.722513  0.879518    0.849856      0.879518\n",
      "f1-score     0.909091    0.821429  0.879518    0.865260      0.875469\n",
      "support    307.000000  191.000000  0.879518  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.880814    0.974026  0.909639    0.927420      0.916564\n",
      "recall       0.986971    0.785340  0.909639    0.886155      0.909639\n",
      "f1-score     0.930876    0.869565  0.909639    0.900220      0.907361\n",
      "support    307.000000  191.000000  0.909639  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.918919    0.993939  0.943775    0.956429      0.947692\n",
      "recall       0.996743    0.858639  0.943775    0.927691      0.943775\n",
      "f1-score     0.956250    0.921348  0.943775    0.938799      0.942864\n",
      "support    307.000000  191.000000  0.943775  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.935780    0.994152  0.955823    0.964966      0.958168\n",
      "recall       0.996743    0.890052  0.955823    0.943398      0.955823\n",
      "f1-score     0.965300    0.939227  0.955823    0.952263      0.955300\n",
      "support    307.000000  191.000000  0.955823  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.947368    0.994286  0.963855    0.970827      0.965363\n",
      "recall       0.996743    0.910995  0.963855    0.953869      0.963855\n",
      "f1-score     0.971429    0.950820  0.963855    0.961124      0.963524\n",
      "support    307.000000  191.000000  0.963855  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.962382    1.000000  0.975904    0.981191      0.976810\n",
      "recall       1.000000    0.937173  0.975904    0.968586      0.975904\n",
      "f1-score     0.980831    0.967568  0.975904    0.974199      0.975744\n",
      "support    307.000000  191.000000  0.975904  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's \n",
    "for i in range(2, 11):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = forest.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c2770",
   "metadata": {},
   "source": [
    "#### - 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67a00436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.811245</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.021525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.045622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.849398</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.050332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.075780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.096554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.126018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.955823</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.138066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.141426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.176838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.979920</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.162163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.985944</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.177533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.989960</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.181549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.989960</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.186222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.191589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.191589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.191589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.200935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.811245           0.789720    0.021525\n",
       "1           3        0.835341           0.789720    0.045622\n",
       "2           4        0.849398           0.799065    0.050332\n",
       "3           5        0.879518           0.803738    0.075780\n",
       "4           6        0.909639           0.813084    0.096554\n",
       "5           7        0.943775           0.817757    0.126018\n",
       "6           8        0.955823           0.817757    0.138066\n",
       "7           9        0.963855           0.822430    0.141426\n",
       "8          10        0.975904           0.799065    0.176838\n",
       "9          11        0.979920           0.817757    0.162163\n",
       "10         12        0.985944           0.808411    0.177533\n",
       "11         13        0.989960           0.808411    0.181549\n",
       "12         14        0.989960           0.803738    0.186222\n",
       "13         15        0.993976           0.813084    0.180892\n",
       "14         16        1.000000           0.808411    0.191589\n",
       "15         17        1.000000           0.808411    0.191589\n",
       "16         18        1.000000           0.808411    0.191589\n",
       "17         19        1.000000           0.803738    0.196262\n",
       "18         20        1.000000           0.799065    0.200935\n",
       "19         21        1.000000           0.803738    0.196262\n",
       "20         22        1.000000           0.803738    0.196262\n",
       "21         23        1.000000           0.803738    0.196262\n",
       "22         24        1.000000           0.803738    0.196262"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f093f",
   "metadata": {},
   "source": [
    "#### After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "232d801b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.set_index('max_depth').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470944e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67560b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec7e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5f704fb",
   "metadata": {},
   "source": [
    "# KNN Exercises\n",
    "#### Continue working in your model file with the titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46829b50",
   "metadata": {},
   "source": [
    "-how do you balance a high K and elimnating outliers?\n",
    "-is there any sort of guideline of ratio for K to datapoints?\n",
    "\n",
    "-KNN seems like it won't be ideal for precision rather reccomendation?\n",
    "\n",
    "If K gets too big you don't have a model anymore, becomes just a baseline guess\n",
    "If K is too small, your model is at the wim of wherever what is nearby will dominate the classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58230c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = acquire.get_titanic_data()\n",
    "df = titanic_data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "194f0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    This function will clean the data etc etc...'''\n",
    "    df = df.drop_duplicates()\n",
    "    cols_to_drop = ['deck', 'embarked', 'class']\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    df['baseline_prediction'] = 0\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True,True])\n",
    "    #df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df = df.drop(columns = ['sex', 'embark_town'])\n",
    "    df.age = df.age.fillna(value=df.age.median())\n",
    "    return df\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c968fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27909906",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d1341d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d45e1d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass   age  sibsp  parch      fare  alone  \\\n",
       "583           583         0       1  36.0      0      0   40.1250      1   \n",
       "165           165         1       3   9.0      0      2   20.5250      0   \n",
       "50             50         0       3   7.0      4      1   39.6875      0   \n",
       "259           259         1       2  50.0      0      1   26.0000      0   \n",
       "306           306         1       1  28.0      0      0  110.8833      1   \n",
       "\n",
       "     baseline_prediction  sex_male  embark_town_Queenstown  \\\n",
       "583                    0         1                       0   \n",
       "165                    0         1                       0   \n",
       "50                     0         1                       0   \n",
       "259                    0         0                       0   \n",
       "306                    0         0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "583                        0  \n",
       "165                        1  \n",
       "50                         1  \n",
       "259                        1  \n",
       "306                        0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98a88f86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id               0\n",
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "baseline_prediction        0\n",
       "sex_male                   0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8931b0",
   "metadata": {},
   "source": [
    "### 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07f40ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4baec11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2effcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a528428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0411cca",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77204e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.75\n",
      "[[266  41]\n",
      " [ 85 106]]\n",
      "------------------------------------\n",
      "n_neighbor = 5 & weights = uniform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.757835</td>\n",
       "      <td>0.721088</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.739462</td>\n",
       "      <td>0.743741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.866450</td>\n",
       "      <td>0.554974</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.710712</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.627219</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.717865</td>\n",
       "      <td>0.738979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.757835    0.721088  0.746988    0.739462      0.743741\n",
       "recall       0.866450    0.554974  0.746988    0.710712      0.746988\n",
       "f1-score     0.808511    0.627219  0.746988    0.717865      0.738979\n",
       "support    307.000000  191.000000  0.746988  498.000000    498.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 5\n",
    "weights = 'uniform'\n",
    "knn1 = KNeighborsClassifier(n_neighbors, weights)\n",
    "knn1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn1.predict(X_train)\n",
    "y_pred_proba = knn1.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn1.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('------------------------------------')\n",
    "print(f'n_neighbor = {n_neighbors} & weights = {weights}')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c891eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed458a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36c1bcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13569bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb77a2",
   "metadata": {},
   "source": [
    "### 3.Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c18a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d33297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The True Negative Rate is {TNR[0]}')\n",
    "print(f'The True Positive Rate is {TPR[0]}')\n",
    "print(f'The False Negative Rate is {FNR[0]}')\n",
    "print(f'The False Positive Rate is {FPR[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e5251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8fdd0a2",
   "metadata": {},
   "source": [
    "### 4.Run through steps 2-4 setting k to 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a76a2058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.69\n",
      "[[282  25]\n",
      " [127  64]]\n",
      "------------------------------------\n",
      "n_neighbor = 10 & weights = uniform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.689487</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.704294</td>\n",
       "      <td>0.700845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.918567</td>\n",
       "      <td>0.335079</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.626823</td>\n",
       "      <td>0.694779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.622426</td>\n",
       "      <td>0.660926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.689487    0.719101  0.694779    0.704294      0.700845\n",
       "recall       0.918567    0.335079  0.694779    0.626823      0.694779\n",
       "f1-score     0.787709    0.457143  0.694779    0.622426      0.660926\n",
       "support    307.000000  191.000000  0.694779  498.000000    498.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 10\n",
    "weights = 'uniform'\n",
    "knn2 = KNeighborsClassifier(n_neighbors, weights)\n",
    "knn2.fit(X_train, y_train)\n",
    "y_pred = knn2.predict(X_train)\n",
    "y_pred_proba = knn2.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn2.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('------------------------------------')\n",
    "print(f'n_neighbor = {n_neighbors} & weights = {weights}')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff9664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c97596",
   "metadata": {},
   "source": [
    "### 5.Run through setps 2-4 setting k to 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fb57856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.67\n",
      "[[290  17]\n",
      " [145  46]]\n",
      "------------------------------------\n",
      "n_neighbor = 20 & weights = uniform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.691018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.944625</td>\n",
       "      <td>0.240838</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.674699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.781671</td>\n",
       "      <td>0.362205</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.571938</td>\n",
       "      <td>0.620791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.666667    0.730159  0.674699    0.698413      0.691018\n",
       "recall       0.944625    0.240838  0.674699    0.592732      0.674699\n",
       "f1-score     0.781671    0.362205  0.674699    0.571938      0.620791\n",
       "support    307.000000  191.000000  0.674699  498.000000    498.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "weights = 'uniform'\n",
    "knn3 = KNeighborsClassifier(n_neighbors, weights)\n",
    "knn3.fit(X_train, y_train)\n",
    "y_pred = knn3.predict(X_train)\n",
    "y_pred_proba = knn3.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn3.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('------------------------------------')\n",
    "print(f'n_neighbor = {n_neighbors} & weights = {weights}')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc8f7d",
   "metadata": {},
   "source": [
    "### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ebcff4",
   "metadata": {},
   "source": [
    "- Through data discovery found that uniform preforms better than distance for weights\n",
    "- That a lower n_neighbor preformed better 5 compared to 10&20 (overfitting?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6616c005",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3443eb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b495e9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 21):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997dd1b",
   "metadata": {},
   "source": [
    "Our performance gap is absolutely massive at first\n",
    "From 12-20 the performance is relatively is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "167b76e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'train_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-1557391f7ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmetrics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmetrics_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"difference\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mmetrics_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'train_accuracy'"
     ]
    }
   ],
   "source": [
    "#Mason's code:\n",
    "\n",
    "k_range = range(1, 21)\n",
    "scores = []\n",
    "metrics = []\n",
    "for k in k_range:\n",
    "    titan_knn = KNeighborsClassifier(n_neighbors = k, weights = 'uniform')\n",
    "    titan_knn.fit(X_train, y_train)\n",
    "    scores.append(titan_knn.score(X_validate, y_validate))\n",
    "    in_sample_accuracy = titan_knn.score(X_train, y_train)\n",
    "    out_of_sample_accuracy = titan_knn.score(X_validate, y_validate)\n",
    "    output = {\n",
    "        \"n_neighbors\": k,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0, 5, 10, 15, 20])\n",
    "plt.title('Validate Accuracy')\n",
    "plt.show();\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bde2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c242cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3592a93b",
   "metadata": {},
   "source": [
    "## Logistic Regression Exercises\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d34d9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53fe6f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = acquire.get_titanic_data()\n",
    "df = titanic_data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a0af52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    This function will clean the data etc etc...'''\n",
    "    df = df.drop_duplicates()\n",
    "    cols_to_drop = ['deck', 'embarked', 'class']\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    df['baseline_prediction'] = 0\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True,True])\n",
    "    #df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df = df.drop(columns = ['sex', 'embark_town'])\n",
    "    df.age = df.age.fillna(value=df.age.median())\n",
    "    return df\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c89c175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   age  sibsp  parch     fare  alone  \\\n",
       "0             0         0       3  22.0      1      0   7.2500      0   \n",
       "1             1         1       1  38.0      1      0  71.2833      0   \n",
       "2             2         1       3  26.0      0      0   7.9250      1   \n",
       "3             3         1       1  35.0      1      0  53.1000      0   \n",
       "4             4         0       3  35.0      0      0   8.0500      1   \n",
       "\n",
       "   baseline_prediction  sex_male  embark_town_Queenstown  \\\n",
       "0                    0         1                       0   \n",
       "1                    0         0                       0   \n",
       "2                    0         0                       0   \n",
       "3                    0         0                       0   \n",
       "4                    0         1                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39841495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id               0\n",
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "baseline_prediction        0\n",
       "sex_male                   0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1702af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare2.titanic_split(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b00edabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40def2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3eaa9",
   "metadata": {},
   "source": [
    "### 1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cff2b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting hyperparameters and fitting the model\n",
    "\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "#logit.fit(X_train, y_train) - need to add the featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87fb5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting features\n",
    "features = ['age', 'fare', 'pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "98727a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train[features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4b2f0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a503b883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8d217734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3f0efa83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.35, 0.65],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.65, 0.35],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.85, 0.15],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.25, 0.75],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.55, 0.45],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.55, 0.45],\n",
       "       [0.45, 0.55],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.45, 0.55],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c4c1acf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need baseline \n",
    "baseline= 1 - (train.survived).mean()\n",
    "baseline = round(baseline,3)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "47aef896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       307\n",
      "           1       0.67      0.43      0.53       191\n",
      "\n",
      "    accuracy                           0.70       498\n",
      "   macro avg       0.69      0.65      0.66       498\n",
      "weighted avg       0.70      0.70      0.69       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.70\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617927cd",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a11bc481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       307\n",
      "           1       0.76      0.73      0.74       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.79      0.79       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       307\n",
      "           1       0.76      0.73      0.74       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.79      0.79       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.81\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "features2 = ['age', 'fare', 'pclass', 'sex_male']\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "\n",
    "logit.fit(X_train[features2], y_train)\n",
    "y_pred = logit.predict(X_train[features2])\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features2], y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba681223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3992403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall = sensitivity\n",
    "\n",
    "#messing with C changes your slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612a2a5",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#considered making a function - try later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b49a9c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       307\n",
      "           1       0.00      0.00      0.00       191\n",
      "\n",
      "    accuracy                           0.62       498\n",
      "   macro avg       0.31      0.50      0.38       498\n",
      "weighted avg       0.38      0.62      0.47       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       307\n",
      "           1       0.00      0.00      0.00       191\n",
      "\n",
      "    accuracy                           0.62       498\n",
      "   macro avg       0.31      0.50      0.38       498\n",
      "weighted avg       0.38      0.62      0.47       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.62\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#solely based on age which is our baseline - wanting to see spread\n",
    "\n",
    "features3 = ['age']\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "\n",
    "logit.fit(X_train[features3], y_train)\n",
    "y_pred = logit.predict(X_train[features3])\n",
    "\n",
    "print(classification_report(yA_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features3], y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "28457558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       307\n",
      "           1       0.79      0.68      0.73       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.78      0.79       498\n",
      "weighted avg       0.80      0.81      0.80       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       307\n",
      "           1       0.79      0.68      0.73       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.78      0.79       498\n",
      "weighted avg       0.80      0.81      0.80       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.81\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#No specific features within X_train\n",
    "\n",
    "\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bbf6d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.75      0.69      0.72       191\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.78       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.75      0.69      0.72       191\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.78       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.79\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#Same as above w/ C=.999\n",
    "\n",
    "logit = LogisticRegression(C=.999, random_state=123)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "692053d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77       307\n",
      "           1       0.68      0.18      0.28       191\n",
      "\n",
      "    accuracy                           0.65       498\n",
      "   macro avg       0.66      0.56      0.53       498\n",
      "weighted avg       0.66      0.65      0.58       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77       307\n",
      "           1       0.68      0.18      0.28       191\n",
      "\n",
      "    accuracy                           0.65       498\n",
      "   macro avg       0.66      0.56      0.53       498\n",
      "weighted avg       0.66      0.65      0.58       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.65\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#Same as above w/ C=.001\n",
    "\n",
    "logit = LogisticRegression(C=0.001, random_state=123)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "327d0246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.80\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#solely based on age which is our baseline - wanting to see spread\n",
    "\n",
    "features4 = ['age','sex_male','alone']\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "\n",
    "logit.fit(X_train[features4], y_train)\n",
    "y_pred = logit.predict(X_train[features4])\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features4], y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a0fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c364cf",
   "metadata": {},
   "source": [
    "### 4. Use you best 3 models to predict and evaluate on your validate sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b387574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53997e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72217a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "906580aa",
   "metadata": {},
   "source": [
    "### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d76eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e80322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9941fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
