{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e968b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import prepare2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54eae3",
   "metadata": {},
   "source": [
    "# Having extreme difficulty with my code - Using Adam's to help format for future exercises to stay update with material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92643c63",
   "metadata": {},
   "source": [
    "### Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = acquire.get_titanic_data()\n",
    "df = titanic_data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236d295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pulled and updated from prepare.py - was having some issues with the string 'sex' when splitting\n",
    "\n",
    "def clean_data(df):\n",
    "    '''\n",
    "    This function will clean the data etc etc...'''\n",
    "    df = df.drop_duplicates()\n",
    "    cols_to_drop = ['deck', 'embarked', 'class']\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    df['baseline_prediction'] = 0\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True,True])\n",
    "    #df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df = df.drop(columns = ['sex', 'embark_town'])\n",
    "    df.age = df.age.fillna(value=df.age.median())\n",
    "    return df\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3032c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.age = df.age.fillna(value=df.age.median())\n",
    "# df = df.drop(columns = ['deck', 'embarked'])\n",
    "# df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12415a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce obvious noise\n",
    "df = df.set_index(\"passenger_id\")\n",
    "df = df.drop(columns=[\"class\", \"embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e795e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about nulls?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19211436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop deck because there are far too many nulls\n",
    "df = df.drop(columns=[\"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffe0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill embark_town with the most common observation\n",
    "df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the observations with missing age\n",
    "# My first thought was empty age values might indicate children\n",
    "# Looks like most of these individuals were traveling alone\n",
    "no_age_info = df[df.age.isna()]\n",
    "no_age_info.alone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed4d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Time to encode the encodeable!\n",
    "dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# Drop the original columns we encoded\n",
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "\n",
    "# Stitch the df and the dummy_df together again\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a22172",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d87b4",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline is simpliest model\n",
    "#runs a .mode on y_train and saves to baseline\n",
    "#what is the likely prediction here? more likely someone died or survived?\n",
    "#simplest model is featureless model were they on the titanic? did they die? - will be right 62% of th time\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11610dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #baseline column and setting values to 0 (aka died), most common value in survived\n",
    "# train['baseline']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_class_report = classification_report(train.survived, train.baseline, zero_division=True)\n",
    "# print(baseline_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0eb11a",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1394ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = tree1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a85d3",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f948e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix - actual on left, predicted on top\n",
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea82a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89cf8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c05f9ad1",
   "metadata": {},
   "source": [
    "one depth tree is able to get it right 80% of the time - could be asking are you male or female?\n",
    "\n",
    "-add confusion matrix - (actual on left, predicted on the top = reference to how Adam has his code lined)\n",
    "code18 isn't necessary just depends on how you like to visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0955045",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16224a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not-survived is our positive case\n",
    "TP = 265\n",
    "FP = 58\n",
    "FN = 42\n",
    "TN = 133\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a3fb9",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eeb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the difference is the overfitting of the model\n",
    "\n",
    "#how do we make the judgement call on which model works best? - no hard and fast anwser \n",
    "#focus on the difference number (<.10) could offer us models that aren't overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4489ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's \n",
    "for i in range(2, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546157f",
   "metadata": {},
   "source": [
    "#### 6. Which model performs better on your in-sample data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth of 15+ produces the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb6eba",
   "metadata": {},
   "source": [
    "#### 7. Which model performs best on your out-of-sample data, the validate set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f223406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c15b4b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20af730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dddb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f5dbd4b",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "#### - 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77517b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b82e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce obvious noise\n",
    "df = df.set_index(\"passenger_id\")\n",
    "df = df.drop(columns=[\"class\", \"embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop deck because there are far too many nulls\n",
    "df = df.drop(columns=[\"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239851ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill embark_town with the most common observation\n",
    "df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65427f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the observations with missing age\n",
    "# My first thought was empty age values might indicate children\n",
    "# Looks like most of these individuals were traveling alone\n",
    "no_age_info = df[df.age.isna()]\n",
    "no_age_info.alone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5740e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how similar this group is to the population\n",
    "for column in df.drop(columns=[\"age\", \"fare\"]).columns:\n",
    "    print(column)\n",
    "    print(\"Population:\")\n",
    "    print(df[column].value_counts(normalize=True))\n",
    "    print(\"No age\")\n",
    "    print(no_age_info[column].value_counts(normalize=True))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to encode the encodeable!\n",
    "dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# Drop the original columns we encoded\n",
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "\n",
    "# Stitch the df and the dummy_df together again\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to split!\n",
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b6b19",
   "metadata": {},
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddecacd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b9635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aadd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Time to encode the encodeable!\n",
    "# dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# # Drop the original columns we encoded\n",
    "# df = df.drop(columns=[\"sex\", \"embark_town\", 'embarked'])\n",
    "\n",
    "# # Stitch the df and the dummy_df together again\n",
    "# df = pd.concat([df, dummy_df], axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80dc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6fc021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e923ebad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f682e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=123, \n",
    "                                            stratify=df.survived)\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=123,\n",
    "                                       stratify=train_validate[survived])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd54984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab874d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369901e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77aa6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf = 1, max_depth=10, \n",
    "                            random_state=123)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f805a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77bec6",
   "metadata": {},
   "source": [
    "#### - 2. Evaluate your results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1321bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "735fe863",
   "metadata": {},
   "source": [
    "#### - 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd265aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd4b1397",
   "metadata": {},
   "source": [
    "#### - 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84d80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af2c2770",
   "metadata": {},
   "source": [
    "#### - 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a00436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "272f093f",
   "metadata": {},
   "source": [
    "#### After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d801b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470944e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67560b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec7e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5f704fb",
   "metadata": {},
   "source": [
    "# KNN Exercises\n",
    "#### Continue working in your model file with the titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46829b50",
   "metadata": {},
   "source": [
    "-how do you balance a high K and elimnating outliers?\n",
    "-is there any sort of guideline of ratio for K to datapoints?\n",
    "\n",
    "-KNN seems like it won't be ideal for precision rather reccomendation?\n",
    "\n",
    "If K gets too big you don't have a model anymore, becomes just a baseline guess\n",
    "If K is too small, your model is at the wim of wherever what is nearby will dominate the classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58230c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = acquire.get_titanic_data()\n",
    "df = titanic_data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "194f0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    This function will clean the data etc etc...'''\n",
    "    df = df.drop_duplicates()\n",
    "    cols_to_drop = ['deck', 'embarked', 'class']\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    df['baseline_prediction'] = 0\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True,True])\n",
    "    #df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df = df.drop(columns = ['sex', 'embark_town'])\n",
    "    df.age = df.age.fillna(value=df.age.median())\n",
    "    return df\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c968fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27909906",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d1341d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d45e1d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass   age  sibsp  parch      fare  alone  \\\n",
       "583           583         0       1  36.0      0      0   40.1250      1   \n",
       "165           165         1       3   9.0      0      2   20.5250      0   \n",
       "50             50         0       3   7.0      4      1   39.6875      0   \n",
       "259           259         1       2  50.0      0      1   26.0000      0   \n",
       "306           306         1       1  28.0      0      0  110.8833      1   \n",
       "\n",
       "     baseline_prediction  sex_male  embark_town_Queenstown  \\\n",
       "583                    0         1                       0   \n",
       "165                    0         1                       0   \n",
       "50                     0         1                       0   \n",
       "259                    0         0                       0   \n",
       "306                    0         0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "583                        0  \n",
       "165                        1  \n",
       "50                         1  \n",
       "259                        1  \n",
       "306                        0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98a88f86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id               0\n",
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "baseline_prediction        0\n",
       "sex_male                   0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8931b0",
   "metadata": {},
   "source": [
    "### 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07f40ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4baec11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2effcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a528428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0411cca",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77204e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.75\n",
      "[[266  41]\n",
      " [ 85 106]]\n",
      "------------------------------------\n",
      "n_neighbor = 5 & weights = uniform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.757835</td>\n",
       "      <td>0.721088</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.739462</td>\n",
       "      <td>0.743741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.866450</td>\n",
       "      <td>0.554974</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.710712</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.627219</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.717865</td>\n",
       "      <td>0.738979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.757835    0.721088  0.746988    0.739462      0.743741\n",
       "recall       0.866450    0.554974  0.746988    0.710712      0.746988\n",
       "f1-score     0.808511    0.627219  0.746988    0.717865      0.738979\n",
       "support    307.000000  191.000000  0.746988  498.000000    498.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 5\n",
    "weights = 'uniform'\n",
    "knn1 = KNeighborsClassifier(n_neighbors, weights)\n",
    "knn1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn1.predict(X_train)\n",
    "y_pred_proba = knn1.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn1.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('------------------------------------')\n",
    "print(f'n_neighbor = {n_neighbors} & weights = {weights}')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c891eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed458a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36c1bcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13569bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb77a2",
   "metadata": {},
   "source": [
    "### 3.Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c18a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d33297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The True Negative Rate is {TNR[0]}')\n",
    "print(f'The True Positive Rate is {TPR[0]}')\n",
    "print(f'The False Negative Rate is {FNR[0]}')\n",
    "print(f'The False Positive Rate is {FPR[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e5251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8fdd0a2",
   "metadata": {},
   "source": [
    "### 4.Run through steps 2-4 setting k to 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a76a2058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.69\n",
      "[[282  25]\n",
      " [127  64]]\n",
      "------------------------------------\n",
      "n_neighbor = 10 & weights = uniform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.689487</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.704294</td>\n",
       "      <td>0.700845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.918567</td>\n",
       "      <td>0.335079</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.626823</td>\n",
       "      <td>0.694779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.622426</td>\n",
       "      <td>0.660926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.689487    0.719101  0.694779    0.704294      0.700845\n",
       "recall       0.918567    0.335079  0.694779    0.626823      0.694779\n",
       "f1-score     0.787709    0.457143  0.694779    0.622426      0.660926\n",
       "support    307.000000  191.000000  0.694779  498.000000    498.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 10\n",
    "weights = 'uniform'\n",
    "knn2 = KNeighborsClassifier(n_neighbors, weights)\n",
    "knn2.fit(X_train, y_train)\n",
    "y_pred = knn2.predict(X_train)\n",
    "y_pred_proba = knn2.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn2.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('------------------------------------')\n",
    "print(f'n_neighbor = {n_neighbors} & weights = {weights}')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff9664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c97596",
   "metadata": {},
   "source": [
    "### 5.Run through setps 2-4 setting k to 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fb57856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.67\n",
      "[[290  17]\n",
      " [145  46]]\n",
      "------------------------------------\n",
      "n_neighbor = 20 & weights = uniform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.691018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.944625</td>\n",
       "      <td>0.240838</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.674699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.781671</td>\n",
       "      <td>0.362205</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.571938</td>\n",
       "      <td>0.620791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.666667    0.730159  0.674699    0.698413      0.691018\n",
       "recall       0.944625    0.240838  0.674699    0.592732      0.674699\n",
       "f1-score     0.781671    0.362205  0.674699    0.571938      0.620791\n",
       "support    307.000000  191.000000  0.674699  498.000000    498.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 20\n",
    "weights = 'uniform'\n",
    "knn3 = KNeighborsClassifier(n_neighbors, weights)\n",
    "knn3.fit(X_train, y_train)\n",
    "y_pred = knn3.predict(X_train)\n",
    "y_pred_proba = knn3.predict_proba(X_train)\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn3.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('------------------------------------')\n",
    "print(f'n_neighbor = {n_neighbors} & weights = {weights}')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc8f7d",
   "metadata": {},
   "source": [
    "### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ebcff4",
   "metadata": {},
   "source": [
    "- Through data discovery found that uniform preforms better than distance for weights\n",
    "- That a lower n_neighbor preformed better 5 compared to 10&20 (overfitting?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6616c005",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3443eb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b495e9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 21):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997dd1b",
   "metadata": {},
   "source": [
    "Our performance gap is absolutely massive at first\n",
    "From 12-20 the performance is relatively is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "167b76e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAGLCAYAAABeJUFCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmWElEQVR4nO3de5hcd33f8fcHWcQCIwmwDMiuLdOAgKfB2CyFpCQYJ1jglGDCJSE2BRpwuCRtmkS2RZOHSy61K5KUpglgQjA1CZDYwuAAEfcAoaGskC84IDCuL6wwyCZrySBAlr/945x1RsOuvCPvzGj3vF/PM8/s/M5lvmdnZ+cz5/c756SqkCRJ3XOfcRcgSZLGwxAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQBqCJO9PsjPJrO+xJD+VpJK8YJ7ruzjJdT2P17XLn30Pyz20ne/FA9b/uCSvTbJykOUGWP+H2rpeMoz1S5ofQ4A0HJcADwNOm2P6WcAdwPsOcf3fAH4c+LtDXP6ePA54DbDgISDJQ4CfaR++cKHXL2n+DAHScFwB3E7zYX+AJPcFngdcVlXfPZSVV9X3q+ofq+rWe1fmWLwAOIImwDwlyXFjrucASVaMuwZpVAwB0hBU1feAS4GfT3Jk3+QzgAcC70yyIsn/TPKlJN9J8vUk705y7MHWP1d3QJLzkky16/o7YN0sy56d5O+T3Jrk9iSfS/KzPdNfDLy9fXhz+zzVM/0BSf44yc1Jvp9kR5KXzf+3wwuBa4GNNP+DfmmWGle2z3Fj+xw3JfmLvnmekOSDSabb7d3e273S1v3bfcuc2rY/uW++1yT53SQ7ge+07Y9M8pdtDXuTfCXJBf0hIY1fS/LFJN9LsivJ3yY5IckxSX6Q5BWzbOO7knxxgN+btOAMAdLwXEKzO/2Zfe1nAzuBjwMrgCNpdr2fAfwGcALwD7OEh4NK8nLgAuAy4NnA54D3zDLrOuDdNN/Inwf8A3BFkme00z8A/F7788/RdDv8ePscy4GtwC8CfwD8LE2Xxpvb57+nGh8NnAL8ZVV9Ebiavi6Bdk/Jx4CXAH9C83s5H1jVM8+PA58GHgS8HHgWze/7hHuqYQ6/AjweOAf4hbbtWOD/Af8JeDrwhzSv3dv7ln0j8D/ams8EXtYut6aqvgW8t23r3cYH0bxGbz3EeqWFUVXevHkbwg0IcCNweU/bKmAvsHmOZZYBxwB3Ac/uab8YuK7n8TqggLPbx/cBvg78dd/63tDO9+I5nu8+NLvm3w+8r6f9xe1yx/XN/x/a2k7pa38rcAtwn3v4nfxBu/wJ7eON7fOc1DPPS9u20w6yns8AXwXue5B5CvjtvrZT2/Yn9813PXDEPbyWRwDPBfYDD27bH9Fuz+sOsuxp7XOc0tP268D3gAeN++/UW7dv7gmQhqSqCvhL4BlJHtg2P4fmm/87Z+Zrd89PJtkN3Al8k+ZDZ/0AT/evaL65vrev/a/7Z0zy6CSXJvlG+3z7aPZWzOf5NgA7gKuTHDFzo9k78BDgR+daMEloxkh8pqpubJv/iuZDtLdb42eAG6rq43Os5340eybeWVU/mEfN8/Ghqrqz73mObLsJvkoT3PYBf0MTnB7RzvbTNK/VAV0Vvdrt+ApNuJnxyzRjQr69QPVLh8QQIA3XJcDMQEBoPuy+WFVXASR5djvPlcDzgScCT6D5tjlId8DD2vtv9bV/s/dBkgcAH6b5wP9N4Mnt871vns93DPAomg/E3tvftNMffJBlfwo4HnhfktVJVtP0v38W+KX8y+GUDwamDrKeB9L87zrYPIO6ZZa2C4FXA28DnkHze5rZrT/zu5rZ3p33sP6LaLZxRduV8W+wK0CHgSPGXYC0lFXVl5J8ATgryQeApwCbemZ5LrCjqu7+lpjkoTTdAoP4Rnt/TF/7Q/oePwk4DnheVf1jz3PON3DcRrMnYK7zE3z5IMvO9P2/ob31Ow34KHBrW+dc/plm78FBB08C36cJYL3mCimzXVP9ucDbq+qCmYYk/Xs6Zo7OWEvT9TOXi4HfpwmDp9J0Zfz9QeaXRsI9AdLwXQL8JM3gNmh2gc+4H9C/S/tQjp2/mebb6LP72p/f9/h+7f3dz9keondq33zfb+/7w8FWmsF3t1XV5Cy3O2Yrrg0ZzwU+Ajy17/YzNHsEZoLFR4F1SZ4627qqOazys8DZ7SDCudwEPKav7RmzzTiH+bw2H6cJEP/xYCuqqttojhb5NZrX5M/b7iJprNwTIA3fu2i++b4K+GRVfb1n2lbgTUkuoPmA/AngRTR99fNWVXcl+X3gT5O8kWaE/7/jX7ohZvwfYE873+uB1cBraXat9+59+FJ7/6ok7wHurKpJmrEMvwx8IskbaA71uz9NF8GTquq5c5T4TJpBkX9aVZ/sn5jkMuA5SV5JE5peAbw3ye8C24E1wHOqaibUnAd8Avj7dnu/RbOLfUVVXdjO8x7g/CTntut4OnOfvGk2W4GXtIfx3URzKOOjemeoqq8m+V/AbydZRXPug+U0YwXe2f7OZryZ5oiGfcA7BqhDGp5xj0z05q0LN+CDtN8Y+9qX0RzW9w2ab8NbgUfSjBx/bc98F3OQowN62jfR7BH4Lk3f/4/Td3QA8DTgqvY5dtAcCfBmmsF4vev6XZq+8rtoxzm27fej2bV9Hc035W/RfLi96iDb//52vuVzTD+1rfMF7eNVNIcHTrXPcRPwtr5lnthu4x6asy9uB36hZ/oK4M9oxkVMA38O/HtmPzrgt2epaQ3NWIdpmm6Qt7a/uwJO7ZkvwH+hCU7fb7fz/cDxs6zzW8Cl4/579OZt5pYq90hJ0rAl+bc05254elVtHXc9EmAIkKRhSrIW+NfAfwceAPxY+Y9XhwkHBkrScJ0DfJJm7MQLDQA6nLgnQJKkjnJPgCRJHWUIkCSpozp3noCjjz661q1bN+4yJEkaiW3btt1aVWtmm9a5ELBu3TomJyfveUZJkpaAJHOe0truAEmSOsoQIElSRxkCJEnqKEOAJEkdZQiQJKmjDAGSJHXUyEJAkmVJNifZlWRPksuSHH2Q+Y9J8o4ktyXZneTK9kIcM9OPSPK6JDcm+U6SryV5xmi2RpKkxW+UewLOB55Fcw3w49q2S2abMcmRwMdoriO+HlgNnEVzzfAZbwZOBzYARwE/SXM9b0mSNA+jPFnQOcDrq+p6gCTnAtclWVdVN/TN+yKaD/5XVtW+tu3amYlJ1gO/DDy6qr7cNu8cYu2SJC05IwkBSVYBxwPbZtqq6mtJdgOPBW7oW+SpwD8Bb0nyLGAXcFFV/VHP9N3AGUk+BuwHPgCcW1V7Znn+c2hCCMcff/wCbpkkaaFcvn2KzVt3sHN6L2tXr2DjhvWcefKx4y5rZMax/aPqDljZ3t/e1z7dM63X0TS7+q8CHgacDbw6yVk901cCTwAeTdPF8Djgj35oTUBVXVRVE1U1sWbNrKdPliSN0eXbp9i05RqmpvdSwNT0XjZtuYbLt0+Nu7SRGNf2jyoEzHw7X9XXvprmG/1s809V1Rur6gdVNQm8k2ZMQe/6fqeqdlfVN4ALe6ZLkhaRzVt3sHff/gPa9u7bz+atO8ZU0WiNa/tHEgKqahq4CThlpi3Jw2m+zV89yyJXAjXbqnqmM8s8sy0jSTrM7ZzeO1D7UjOu7R/l0QEXAeclOTHJSppv7ltnGRQIcDHw4CSvag8tPInm6IAt7fRPA9cAr0ty/yTHABt7pkuSFpG1q1cM1L7UjGv7RxkCLgCuAD4PTAHLaPr6SXJWkrsP/6uqG4EzgJfSdBdcCry2qt7TTr8LeCbwIOCbwHaaQYe/NaqNkSQtnI0b1rNi+bID2lYsX8bGDevHVNFojWv7U9WtPegTExM1OTk57jIkSX08OmA4259kW1VNzDrNECBJ0tJ1sBDgtQMkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaOOGHcBkqThunz7FJu37mDn9F7Wrl7Bxg3rOfPkYw+7dQ7LYqp11AwBkrSEXb59ik1brmHvvv0ATE3vZdOWawAO+YNwGOsclsVU6zjYHSBJS9jmrTvu/gCcsXfffjZv3XFYrXNYFlOt42AIkKQlbOf03oHax7XOYVlMtY6DIUCSlrC1q1cM1D6udQ7LYqp1HAwBkrSEbdywnhXLlx3QtmL5MjZuWH9YrXNYFlOt4+DAQElawmYGvy3k6PhhrHNYFlOt45CqGncNIzUxMVGTk5PjLkOSpJFIsq2qJmabZneAJEkdZQiQJKmjDAGSJHWUIUCSpI4yBEiS1FGGAEmSOsrzBEiSNKClcmVCQ4AkSQNYSlcmtDtAkqQBLKUrExoCJEkawFK6MqEhQJKkASylKxMaAiRJGsBSujKhAwMlSRrAUroyoSFAkqQBnXnysYvyQ7+f3QGSJHWUIUCSpI4yBEiS1FGGAEmSOsoQIElSR40sBCRZlmRzkl1J9iS5LMnRB5n/mCTvSHJbkt1Jrkyydpb5HpvkB0k+OtwtkCRpaRnlnoDzgWcBTwSOa9sumW3GJEcCHwN+AKwHVgNnAXf0zXcE8BfAp4dSsSRJS9gozxNwDvD6qroeIMm5wHVJ1lXVDX3zvojmg/+VVbWvbbt2lnVuAj4PfBN48jCKliRpqRrJnoAkq4DjgW0zbVX1NWA38NhZFnkq8E/AW9rugC8n+Y2+df4Y8GLgvGHVLUnSUjaq7oCV7f3tfe3TPdN6HQ2cDlwFPAw4G3h1krPg7m6AtwO/XlW77+nJk5yTZDLJ5K5duw5tCyRJWmJGFQL2tPer+tpX0+wNmG3+qap6Y1X9oKomgXfSjCkAOBf4alVdMZ8nr6qLqmqiqibWrFkzePWSJC1BIxkTUFXTSW4CTgGuBEjycJq9AFfPssiVwMRsq2rvTwdOSXJr+/h+wBHt40dW1bcXrnpJkpamUR4dcBFwXpITk6wELgS2zjIoEOBi4MFJXtUeWngSzdEBW9rpzwMeAzyuvb0Z+Fz78/TQtkCSpCVklCHgAuAKmtH8U8Aymr5+kpyV5O7D/6rqRuAM4KU03QWXAq+tqve003dV1ddnbu08328f3zXCbZIkadFKVd3zXEvIxMRETU5OjrsMSZJGIsm2qpqti93TBkuS1FWGAEmSOsoQIElSRxkCJEnqKEOAJEkdZQiQJKmjDAGSJHWUIUCSpI4yBEiS1FGGAEmSOsoQIElSRxkCJEnqKEOAJEkdZQiQJKmjDAGSJHWUIUCSpI4yBEiS1FGGAEmSOsoQIElSRxkCJEnqKEOAJEkdZQiQJKmjDAGSJHWUIUCSpI4yBEiS1FGGAEmSOsoQIElSRxkCJEnqKEOAJEkdZQiQJKmjDAGSJHWUIUCSpI4yBEiS1FGGAEmSOsoQIElSRxkCJEnqKEOAJEkdZQiQJKmjDAGSJHWUIUCSpI4yBEiS1FGGAEmSOsoQIElSRxkCJEnqqCPGXYDU7/LtU2zeuoOd03tZu3oFGzes58yTjx13WT9ksdSpxcO/KY2aIUCHlcu3T7FpyzXs3bcfgKnpvWzacg3AYfXPcLHUqcXDvymNg90BOqxs3rrj7n+CM/bu28/mrTvGVNHsFkudWjz8m9I4GAJ0WNk5vXeg9nFZLHVq8fBvSuMwshCQZFmSzUl2JdmT5LIkRx9k/mOSvCPJbUl2J7kyydp22iOTXJpkql3XtUleOqpt0fCsXb1ioPZxWSx1avHwb0rjMMo9AecDzwKeCBzXtl0y24xJjgQ+BvwAWA+sBs4C7mhneSDwCeAJwErgV4A3JPn5IdWuEdm4YT0rli87oG3F8mVs3LB+TBXNbrHUqcXDvymNwygHBp4DvL6qrgdIci5wXZJ1VXVD37wvovngf2VV7Wvbrp2ZWFWfAz7XM/9nknwEeAqwZTjlaxRmBkAd7iOkF0udWjz8m9I4pKqG/yTJKmAaOLmqruxpvx14YVW9v2/+d9N825+i2XuwC7ioqv5ojvXfD/gK8JqqetvBapmYmKjJyclD3xhJkhaRJNuqamK2aaPqDljZ3t/e1z7dM63X0cDpwFXAw4CzgVcnOat/xiTLaLoV/h/wv2d78iTnJJlMMrlr165D2gBJkpaaUYWAPe39qr721cDuOeafqqo3VtUPqmoSeCfNXoG7JVkOvIsmKPz7nq6DA1TVRVU1UVUTa9asuRebIUnS0jGSEFBV08BNwCkzbUkeTrMX4OpZFrkSmK2f4u62dvDge4FjgNOrqn8vgyRJOohRHh1wEXBekhOTrAQuBLbOMigQ4GLgwUle1R5aeBLN0QFbAJIcBXwIuC/wjKq6Y5Z1SJKkgxhlCLgAuAL4PM2Av2U0ff0kOSvJ3R/kVXUjcAbwUprugkuB11bVe9pZngOcCjwZ2JXkjvb25hFtiyRJi95Ijg44nHh0gCSpSw52dIAXEFIneHW2hTeM3+liep0WU63SXAwBWvK8OtvCG8bvdDG9ToupVulgvICQljyvzrbwhvE7XUyv02KqVToYQ4CWPK/OtvCG8TtdTK/TYqpVOph5h4AkX02yMckxwyxIWmhenW3hDeN3uphep8VUq3Qwg+wJ+G/AmcBN7WV8Tx9OSdLC8upsC28Yv9PF9Dotplqlg5n3wMCq+gvgL5I8mub4/UuSfBd4G/D2qpoaUo3SveLV2RbeMH6ni+l1Wky1SgdzyOcJSPJImvP2nwzcSXMK39+qqpsXrryF53kCJEldsmBXEUyyPMnzk3wY2E5z+d7TgEcC/0xzRkBJkrQIzLs7IMn/oDl//23AnwO/VFW39kz/VZpLA0uSpEVgkJMFPRR4flV9YraJVXVnkqcsTFmSJGnYBhkY+IvzmGfbvStHkiSNyiDnCdia5LS+ttOS/N3ClyVJkoZtkIGBjwc+1df2KWDWEYeSJOnwNkgIuAtY3te2HMjClSNJkkZlkBCwDfi1vrZfBb6wcOVIkqRRGeTogPOATyZ5Ds35AR4BrAdOHUJdkiRpyOa9J6CqrgYeA1wK7AYuAx5TVVcNqTZJkjREg+wJoKpuATYPqRZJkjRCA4WAJI+i2f2/hp4BgVX1+oUtS5IkDdsgpw1+AXAxcDXw2Pb+JH74sEFJkrQIDHJ0wH8FXlhVTwC+296/HI8OkCRpURokBBwP/E1f2/8GXrhw5UiSpFEZJARMA6van7+Z5NHAg4D7L3RRkiRp+AYJAR8Fnt3+/Nft4/8LfGihi5IkScM3yFUE/2PPw9cAXwZWAu9Y6KIkSdLwzSsEJDkCeB/wnKr6XlUV8FdDrUySJA3VvEJAVd2Z5PHAnUOuR+q8y7dPsXnrDnZO72Xt6hVs3LCeM08+dtxlSVqCBhkTcAnNBYMkDcnl26fYtOUapqb3UsDU9F42bbmGy7dPjbs0SUvQICHgFOC/J7kuyUeTfHjmNqzipK7ZvHUHe/ftP6Bt7779bN66Y0wVSVrKBjlt8Kfw7IDSUO2c3jtQuyTdG4McHfC6YRYiCdauXsHULB/4a1evGEM1kpa6Qa4d8BNzTauqzy5MOVK3bdywnk1brjmgS2DF8mVs3LB+jFVJWqoG6Q74zCxt1d4vW4BapM6bOQrAowMkjcIg3QEHDCJMshb4PeBvF7ooqcvOPPlYP/QljcQgRwccoKp2Av8ZuHDhypEkSaNyyCGg9SPAMQtRiCRJGq1BBga+uq/p/sCzgI8saEWSJGkkBhkY+LS+x3cAfwP88cKVI0mSRmWQgYFPHWYhkiRptAY9T8AtVXV9T9u/Bh7ieQIOf8O4KI0XutFi4d+qNLtBBga+Bcgc7TqMDeOiNF7oRouFf6vS3AYJASdU1dd6G9rHJyxsSVpow7gojRe60WLh36o0t0FCwK4kx/c2JDkB+PbClqSFNoyL0nihGy0W/q1KcxskBLwXuCTJo5IsS/Io4O3AluGUpoUy18Vn7s1FaYaxTmkY/FuV5jZICHgNcAvwT8APgGuBXcDvDKEuLaCNG9azYvmBl3e4txelGcY6pWHwb1Wa2yCHCH4H+IUkvwqsA26oql3DKkwLZxgXpfFCN1os/FuV5paquue5gCSPAPZU1S09bQ8BHlBV1w2pvgU3MTFRk5OT4y5DkqSRSLKtqiZmmzZId8BfAUf3ta1p2+dTxLIkm5PsSrInyWVJ+tfXO/8xSd6R5LYku5Nc2V65cGb6jyb5aJLvJPl6kt8cYFskSeq8QULAI6rqi31t1wKPnOfy59Nca+CJwHFt2yWzzZjkSOBjNGMP1gOrgbNoTlVMkmXAFcCXaILIzwHnJfmFedYiSVLnDRICbp/lm/vRwHfmufw5wIVVdX1V3Q6cCzw9ybpZ5n0RzQf/K6vq1qq6q6qurard7fSfojk/waaq+m5VfYHmpEUvH2B7JEnqtEFCwEeANyU5CqC9/xPgw/e0YJJVwPHAtpm29kRDu4HHzrLIU2mOQnhL2x3w5SS/0TP9JOArVXVHT9sX2vbZnv+cJJNJJnftciyjJEkwWAg4HzgWuC3JzTQnCToB2DiPZVe297f3tU/3TOt1NHA6cBXwMOBs4NVJzmqnP2CAdVFVF1XVRFVNrFmzZh7lSpK09A1yiOCtSf4dMMG/HCL4+Xkuvqe9X9XXvppmb8Bs809V1Rvbx5NJ3kkzpuAv2+nzXZckSZrFIFcRDPBS4KdpBuO1TVBVpx1s2aqaTnITcApwZbu+h9N8c796lkWupAkbP7Sq9v4q4JFJ7t+evwDg5LZdkiTNwyDdAb8P/C5wM/Akmv79x9B+qM/DRTQj+E9MshK4ENhaVTfMMu/FwIOTvKo9tPAkmqMDZk5R/CngRuAPkqxI8jjgV/CKhpIkzdsgIeCXgA1VtRHY196fSdM1MB8X0BzW93lgClhG09dPkrOS3D3Ir6puBM6g2fOwG7gUeG1Vvaedvh94JvBvgNuADwKbq+rdA2yPJEmdNsgZA3dX1cr251uBh1TV/iT/XFUPHGaRC8kzBkqSuuRgZwyc95gAYCrJ8VV1E3A98Iw2DOxbiCIlSdJoDRIC3gQ8HrgJ+GPgciA0VxeUJEmLzCCHCP7Pnp/fleTTwFFV9eWhVCZJkoZqkD0BB6iqry9kIZIkabQGOTpAkiQtIYYASZI6yhAgSVJHGQIkSeooQ4AkSR11yEcHaHgu3z7F5q072Dm9l7WrV7Bxw3rOPPnYcZclSVpiDAGHmcu3T7FpyzXs3bcfgKnpvWzacg2AQUCStKDsDjjMbN664+4AMGPvvv1s3rpjTBVJkpYqQ8BhZuf03oHaJUk6VIaAw8za1SsGapck6VAZAg4zGzesZ8XyZQe0rVi+jI0b1o+pIknSUuXAwMPMzOA/jw6QJA2bIeAwdObJx/qhL0kaOrsDJEnqKEOAJEkdZQiQJKmjDAGSJHWUIUCSpI4yBEiS1FEeIih1gFemlDQbQ4C0xHllSklzsTtAWuK8MqWkuRgCpCXOK1NKmoshQFrivDKlpLkYAqQlzitTSpqLAwOlJc4rU0qaiyFA6gCvTClpNnYHSJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUSMLAUmWJdmcZFeSPUkuS3L0HPOemqSS3NFz+2zfPGck2Zbk9iQ7k/xJkiNHszWSJC1+o9wTcD7wLOCJwHFt2yUHmX9/VR3Vc/uJmQlJjgG2AG8DHgj8W+BU4HeGUbgkSUvRESN8rnOA11fV9QBJzgWuS7Kuqm4YcF3HAT8CvK2q7gK+nuRvgZMWsmBJkpaykewJSLIKOB7YNtNWVV8DdgOPnWOxZUluTnJLkg8k6f2AvxL4EPArSY5IcgLwc8Dlczz/OUkmk0zu2rXr3m+QJElLwKi6A1a297f3tU/3TOv1ZeBxwInAo4CrgY8nWQvQfvu/GPivwPeAG4DtwNtne/KquqiqJqpqYs2aNfdiMyRJWjpGFQL2tPer+tpX0+wNOEBV3VJVV1XVnVU1XVWbgG8DzwBI8lTgHcBLaLoFHkoTJmYNAZIk6YeNJARU1TRwE3DKTFuSh9N8cF89z9XcBaT9+fHA1VX1waraX1XfBN4KPHPBipYkaYkb5dEBFwHnJTkxyUrgQmDrbIMCk5yW5EeT3CfJUUleCzwE2NrO8n+AH0tyehpHAy8DvjCSLZEkaQkYZQi4ALgC+DwwBSwDzgZIclaSO3rmPQn4GE03wvXAk4CnVdXNAFX1D8ArgD+kGWfwT8D3gRePYkMkSVoKUlXjrmGkJiYmanJyctxlSJI0Ekm2VdXEbNM8bbAkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHjSwEJFmWZHOSXUn2JLksydFzzHtqkkpyR8/ts33zHJHkdUluTPKdJF9L8ozRbI0kSYvfKPcEnA88C3gicFzbdslB5t9fVUf13H6ib/qbgdOBDcBRwE8CX1rgmiVJWrKOGOFznQO8vqquB0hyLnBdknVVdcMgK0qyHvhl4NFV9eW2eedCFitJ0lI3kj0BSVYBxwPbZtqq6mvAbuCxcyy2LMnNSW5J8oEkJ/VMe2q77BlJppLclORNSR4wrG2QJGmpGVV3wMr2/va+9umeab2+DDwOOBF4FHA18PEka9vpR7fLPQF4NE0Xw+OAP5rtyZOck2QyyeSuXbsOeSMkSVpKRhUC9rT3q/raV9N8oz9AVd1SVVdV1Z1VNV1Vm4BvAzMD/2bW9ztVtbuqvgFcSDPm4IdU1UVVNVFVE2vWrLm32yJJ0pIwkhBQVdPATcApM21JHk7zbf7qea7mLiDtz1fOrLr/qQ65SEmSOmaURwdcBJyX5MQkK2m+uW+dbVBgktOS/GiS+yQ5KslrgYcAW9tZPg1cA7wuyf2THANsBLaMYkMkSVoKRhkCLgCuAD4PTAHLgLMBkpyV5I6eeU8CPkaz2/964EnA06rqZoCqugt4JvAg4JvAdppBh781ki2RJGkJSFW39qBPTEzU5OTkuMuQJGkkkmyrqonZpnnaYEmSOsoQIElSR43yjIFLzuXbp9i8dQc7p/eydvUKNm5Yz5knHzvusiRJmhdDwCG6fPsUm7Zcw959+wGYmt7Lpi3XABgEJEmLgt0Bh2jz1h13B4AZe/ftZ/PWHWOqSJKkwRgCDtHO6b0DtUuSdLgxBByitatXDNQuSdLhxhBwiDZuWM+K5csOaFuxfBkbN6wfU0WSJA3GgYGHaGbwn0cHSJIWK0PAvXDmycf6oS9JWrTsDpAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdVSqatw1jFSSPcCOcdeheTkauHXcRege+TotHr5Wi8NCv04nVNWa2SZ08doBO6pqYtxF6J4lmfS1Ovz5Oi0evlaLwyhfJ7sDJEnqKEOAJEkd1cUQcNG4C9C8+VotDr5Oi4ev1eIwstepcwMDJUlSo4t7AiRJEoYASZI6qzMhIMmyJJuT7EqyJ8llSY4ed136F0kuTrIvyR09t1eOuy5Bkl9M8ukku5PcOcv0/5Dka0m+m+RzSR4/jjp18NcqyYuT3NX3HnvXuGrtsiQXJrm2fZ12Jnlrkgf1zTP091VnQgBwPvAs4InAcW3bJeMrR3N4R1Ud1XP7s3EXJAD+Gfgz4Nf7JyR5MvAm4BXAA4HLgA8mWTnKAnW3OV+r1vV977EXjK409dgPnA08GDiJ5nPp7TMTR/W+6lIIOAe4sKqur6rbgXOBpydZN96ypMNfVW2tqncB188y+WXAlqr6cFV9H9gMfB949ihrVOMeXisdJqrq1VW1var2VdUu4H8Bp/bMMpL3VSdCQJJVwPHAtpm2qvoasBt47Ljq0qyek+TbSb7Sdt8cNe6CdI9O4sD3VgHb23Ydfv5VkluS3Jzk3UlOHHdBAuCngat7Ho/kfdWJEADM7D65va99umeaxu9PgEfRnDf72cBTgLeOtSLNxwPwvbVYfAr4MWAt8ATge8BHktx/rFV1XJLn0Hzz/889zSN5X3UlBOxp71f1ta+m2Rugw0BVbauqb1bVXVV1LfBfgOcm+ZFx16aD2oPvrUWh7Q79Svseu4Xmg2ct8KQxl9ZZSZ5H82Xn56rqCz2TRvK+6kQIqKpp4CbglJm2JA+nSVRXz7GYxu+u9j5jrUL35CoOfG8FeFzbrsNbtTffY2OQ5CXAW4BnVtUn+iaP5H3ViRDQugg4L8mJ7ejKC4GtVXXDeMvSjPbQptXtz48A/hB4f1V9b6yFaeYQ2yOB+7aPj2xvofkW8/NJfjrJfYHfBI4E3ju+irvrYK9Vkp9Nclz784OAP6W5ZO0/jrPmLkryn4A3ABuq6h9mmWUk76suhYALgCuAzwNTwDKawzN0+Hg5cH2S7wAfpvnH9JLxlqTWC4G9wFaa987e9nZCVX0GeCXNP63bgecDZ1SV3QHjMedrRTP6/P8CdwDX0hye9rSqumMslXbbG2n2Rn+i97wNMxNH9b7y2gGSJHVUl/YESJKkHoYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZKGKskNSTwnh3QYMgRIktRRhgBJkjrKECBpZJLcL8n7knzAy9dK42cIkDQSSR4K/D2wk+ayqd8Zc0lS5xkCJI3CY4DPApdW1Suqav+4C5LkBYQkDVmSG2gugXor8CSvWCcdPtwTIGkUzgeuAT6a5IHjLkZSwxAgaRTuBM6iCQKfTPKQMdcjCUOApBGpqruq6mXAx4BPJTl+3DVJXeeYAEmSOso9AZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkddT/BxYLvVNspyeyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'train_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-1557391f7ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmetrics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmetrics_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"difference\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mmetrics_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'train_accuracy'"
     ]
    }
   ],
   "source": [
    "#Mason's code:\n",
    "\n",
    "k_range = range(1, 21)\n",
    "scores = []\n",
    "metrics = []\n",
    "for k in k_range:\n",
    "    titan_knn = KNeighborsClassifier(n_neighbors = k, weights = 'uniform')\n",
    "    titan_knn.fit(X_train, y_train)\n",
    "    scores.append(titan_knn.score(X_validate, y_validate))\n",
    "    in_sample_accuracy = titan_knn.score(X_train, y_train)\n",
    "    out_of_sample_accuracy = titan_knn.score(X_validate, y_validate)\n",
    "    output = {\n",
    "        \"n_neighbors\": k,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0, 5, 10, 15, 20])\n",
    "plt.title('Validate Accuracy')\n",
    "plt.show();\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bde2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c242cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3592a93b",
   "metadata": {},
   "source": [
    "## Logistic Regression Exercises\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d34d9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53fe6f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = acquire.get_titanic_data()\n",
    "df = titanic_data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a0af52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    This function will clean the data etc etc...'''\n",
    "    df = df.drop_duplicates()\n",
    "    cols_to_drop = ['deck', 'embarked', 'class']\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    df['baseline_prediction'] = 0\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True,True])\n",
    "    #df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "    df = df.drop(columns = ['sex', 'embark_town'])\n",
    "    df.age = df.age.fillna(value=df.age.median())\n",
    "    return df\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c89c175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   age  sibsp  parch     fare  alone  \\\n",
       "0             0         0       3  22.0      1      0   7.2500      0   \n",
       "1             1         1       1  38.0      1      0  71.2833      0   \n",
       "2             2         1       3  26.0      0      0   7.9250      1   \n",
       "3             3         1       1  35.0      1      0  53.1000      0   \n",
       "4             4         0       3  35.0      0      0   8.0500      1   \n",
       "\n",
       "   baseline_prediction  sex_male  embark_town_Queenstown  \\\n",
       "0                    0         1                       0   \n",
       "1                    0         0                       0   \n",
       "2                    0         0                       0   \n",
       "3                    0         0                       0   \n",
       "4                    0         1                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39841495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id               0\n",
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "baseline_prediction        0\n",
       "sex_male                   0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1702af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare2.titanic_split(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b00edabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40def2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3eaa9",
   "metadata": {},
   "source": [
    "### 1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cff2b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting hyperparameters and fitting the model\n",
    "\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "#logit.fit(X_train, y_train) - need to add the featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87fb5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting features\n",
    "features = ['age', 'fare', 'pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "98727a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train[features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4b2f0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a503b883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8d217734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3f0efa83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.35, 0.65],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.65, 0.35],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.85, 0.15],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.25, 0.75],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.55, 0.45],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.55, 0.45],\n",
       "       [0.45, 0.55],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.45, 0.55],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c4c1acf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need baseline \n",
    "baseline= 1 - (train.survived).mean()\n",
    "baseline = round(baseline,3)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "47aef896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       307\n",
      "           1       0.67      0.43      0.53       191\n",
      "\n",
      "    accuracy                           0.70       498\n",
      "   macro avg       0.69      0.65      0.66       498\n",
      "weighted avg       0.70      0.70      0.69       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.70\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617927cd",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a11bc481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       307\n",
      "           1       0.76      0.73      0.74       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.79      0.79       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       307\n",
      "           1       0.76      0.73      0.74       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.79      0.79       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.81\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "features2 = ['age', 'fare', 'pclass', 'sex_male']\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "\n",
    "logit.fit(X_train[features2], y_train)\n",
    "y_pred = logit.predict(X_train[features2])\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features2], y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba681223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3992403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall = sensitivity\n",
    "\n",
    "#messing with C changes your slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612a2a5",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#considered making a function - try later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b49a9c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       307\n",
      "           1       0.00      0.00      0.00       191\n",
      "\n",
      "    accuracy                           0.62       498\n",
      "   macro avg       0.31      0.50      0.38       498\n",
      "weighted avg       0.38      0.62      0.47       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       307\n",
      "           1       0.00      0.00      0.00       191\n",
      "\n",
      "    accuracy                           0.62       498\n",
      "   macro avg       0.31      0.50      0.38       498\n",
      "weighted avg       0.38      0.62      0.47       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.62\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#solely based on age which is our baseline - wanting to see spread\n",
    "\n",
    "features3 = ['age']\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "\n",
    "logit.fit(X_train[features3], y_train)\n",
    "y_pred = logit.predict(X_train[features3])\n",
    "\n",
    "print(classification_report(yA_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features3], y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "28457558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       307\n",
      "           1       0.79      0.68      0.73       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.78      0.79       498\n",
      "weighted avg       0.80      0.81      0.80       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       307\n",
      "           1       0.79      0.68      0.73       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.78      0.79       498\n",
      "weighted avg       0.80      0.81      0.80       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.81\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#No specific features within X_train\n",
    "\n",
    "\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bbf6d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.75      0.69      0.72       191\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.78       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.75      0.69      0.72       191\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.78       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.79\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#Same as above w/ C=.999\n",
    "\n",
    "logit = LogisticRegression(C=.999, random_state=123)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "692053d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77       307\n",
      "           1       0.68      0.18      0.28       191\n",
      "\n",
      "    accuracy                           0.65       498\n",
      "   macro avg       0.66      0.56      0.53       498\n",
      "weighted avg       0.66      0.65      0.58       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77       307\n",
      "           1       0.68      0.18      0.28       191\n",
      "\n",
      "    accuracy                           0.65       498\n",
      "   macro avg       0.66      0.56      0.53       498\n",
      "weighted avg       0.66      0.65      0.58       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.65\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#Same as above w/ C=.001\n",
    "\n",
    "logit = LogisticRegression(C=0.001, random_state=123)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "327d0246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n",
      "-------------------------------------------\n",
      "Accuracy of Logistic Regression Classifier on training set: 0.80\n",
      "Baseline Score is 0.616\n"
     ]
    }
   ],
   "source": [
    "#solely based on age which is our baseline - wanting to see spread\n",
    "\n",
    "features4 = ['age','sex_male','alone']\n",
    "logit = LogisticRegression(C=1, random_state=123)\n",
    "\n",
    "logit.fit(X_train[features4], y_train)\n",
    "y_pred = logit.predict(X_train[features4])\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-------------------------------------------')\n",
    "print('Accuracy of Logistic Regression Classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features4], y_train)))\n",
    "print(f'Baseline Score is {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a0fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c364cf",
   "metadata": {},
   "source": [
    "### 4. Use you best 3 models to predict and evaluate on your validate sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b387574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53997e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72217a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "906580aa",
   "metadata": {},
   "source": [
    "### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d76eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e80322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9941fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
